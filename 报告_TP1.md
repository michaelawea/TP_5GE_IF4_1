# IF4 TP1 实验报告

**学生姓名：** [在此填写姓名]  
**日期：** 2025年10月24日

---

## 2.1 并发任务

### 2.1.1 第一次尝试

**程序：** IF4_TP1_Q21a.ino

#### 问题1：简要描述程序实现的功能和在示波器上获得的结果。解释为什么会得到这个结果。

该程序创建了两个并发任务，任务1（优先级1）控制GPIO 19引脚，任务2（优先级10）控制GPIO 23引脚，两个任务都在无限循环中不断切换其对应引脚的状态。通过示波器观察发现，无论是GPIO 19还是GPIO 23引脚，都能测量到非常正常的高频方波信号，两个任务都能正常执行。从串口日志可以看到，虽然两个任务启动时都在core 1，但运行时FreeRTOS将它们调度到了不同的核心（vTask1在CPU 0，vTask2在CPU 1），因此每个任务都能在各自的核心上独立运行，不会因为优先级差异而导致低优先级任务被"饥饿"

---

#### 问题2：打开串口监视器，你观察到了什么？为什么？

在串口监视器中观察到程序启动时打印"Start"、"vTask1 / core 1 started"和"vTask2 / core 1 started"，两个任务初始都在core 1上创建。约10秒后出现看门狗超时错误"E (10120) task_wdt: Task watchdog got triggered"，错误信息显示当前CPU 0运行vTask1，CPU 1运行vTask2，说明运行过程中FreeRTOS将两个任务调度到了不同的核心上。看门狗错误的原因是两个任务在无限循环中持续占用各自的CPU核心而没有任何延迟操作，导致CPU 0上的空闲任务IDLE0无法执行来喂看门狗，最终触发看门狗复位。在看门狗触发前的10秒内两个任务能正常运行在不同核心上并切换GPIO状态，这解释了为什么在示波器上能观察到两个引脚都有正常的方波信号

---

### 2.1.2 两个并发任务，变体

**程序：** IF4_TP1_Q21b.ino

#### 问题1：与前一个程序有什么区别？

与Q21a程序相比，主要区别在于Q21b使用了`xTaskCreatePinnedToCore()`函数强制将两个任务都固定分配到core 0上运行，而不是让FreeRTOS自动调度任务到不同核心。此外，两个任务的GPIO引脚分配交换了（oscillo1=23，oscillo2=19），并且在每个任务的无限循环中增加了一个内部for循环来连续切换1000次引脚状态。

#### 问题2：通过示波器和串口监视器观察，对运行有什么影响？

通过示波器观察到GPIO 19（channel 1）有正常的方波信号，但GPIO 23完全没有信号输出。串口日志显示只有"[INFO] vTask2 / core 0 started"，没有看到vTask1的启动信息，并且约10秒后出现看门狗错误"E (10118) task_wdt: Task watchdog got triggered"，错误信息显示CPU 0运行Task2，CPU 1运行IDLE1空闲任务。这说明高优先级的Task2（优先级10）完全占用了core 0，导致低优先级的Task1（优先级1）根本无法得到执行机会，甚至连启动信息都没有打印出来。由于Task1控制GPIO 23，所以在示波器上看不到该引脚的任何信号。这就是典型的任务"饥饿"现象：当两个不同优先级的任务被强制在同一个核心上运行时，低优先级任务会被高优先级任务完全阻塞而无法执行。

#### 问题3：如何避免这个问题？

避免任务饥饿问题的方法很简单，就是修改`xTaskCreatePinnedToCore()`函数的最后一个参数，将两个任务分配到不同的核心上运行。具体做法是将一个任务的核心参数设为0，另一个设为1，这样Task1在core 0上运行，Task2在core 1上运行，两个任务就可以并行执行而不会相互阻塞。此外，也可以使用普通的`xTaskCreate()`函数让FreeRTOS自动进行核心分配。另一种方法是在高优先级任务中添加延迟函数（如`vTaskDelay()`），让出CPU时间给低优先级任务执行，但这种方法不如多核分配效果好。

#### 问题4：修改两个任务的优先级，将它们设置为相同的值。你观察到了什么？

当将两个任务的优先级设置为相同值并且都固定在core 0上运行时，在示波器上观察到信号出现不稳定的情况：有时只能看到GPIO 19的信号而没有GPIO 23的信号，有时则相反只有GPIO 23的信号而没有GPIO 19的信号，这两种情况会不断反复切换，甚至出现震荡等各种不确定的状态。这是因为相同优先级的任务在同一个核心上运行时，FreeRTOS调度器会采用时间片轮转方式分配CPU时间，但由于任务没有主动让出CPU（没有延迟或阻塞操作），调度行为变得不可预测，导致某一时刻只有一个任务能够持续执行，而另一个任务被阻塞，并且这种状态会随机变化。

---

## 2.2 周期性任务

### 2.2.1 第一种方法

**程序：** IF4_TP1_Q22a.ino

#### 问题1：与前一个程序有什么区别？

与Q21b程序相比，Q22a的主要区别在于：首先，两个任务被分配到不同的核心上运行（Task1在core 0，Task2在core 1），避免了任务饥饿问题；其次，每个任务在完成工作循环（切换GPIO状态nb_iterations次）后都调用了`vTaskDelay()`函数，Task1延迟10ms，Task2延迟20ms，这样任务会主动让出CPU并进入阻塞状态，等待指定时间后再被唤醒继续执行，从而实现周期性执行的效果。

#### 问题2：任务1和任务2获得的周期是多少？解释原因。

通过示波器测量，GPIO 19（Task1）的信号周期约为26.8ms，GPIO 23（Task2）的信号周期约为36.8ms，这远大于预期的10ms和20ms周期。造成这个结果的原因是实际周期不仅包括`vTaskDelay()`设定的延迟时间，还包括任务的工作执行时间。每个任务需要完成nb_iterations=30000次GPIO切换操作后才会调用延迟函数，这个计算过程本身需要消耗大量时间。对于Task1，实际周期 = 工作时间（约16.8ms）+ 延迟时间（10ms）≈ 26.8ms；对于Task2，实际周期 = 工作时间（约16.8ms）+ 延迟时间（20ms）≈ 36.8ms。可以看到两个任务的工作时间基本相同（都是30000次循环），只是延迟时间不同，导致最终周期相差约10ms。

#### 问题3：如果强制两个任务在同一个核心上运行，会发生什么？

如果将两个任务都强制在同一个核心上运行，由于Task2的优先级（10）高于Task1的优先级（1），会出现以下情况：当Task1正在执行时，如果Task2的延迟时间到期需要运行，高优先级的Task2会立即抢占CPU，打断Task1的执行；Task2完成其工作循环并再次调用`vTaskDelay()`进入阻塞状态后，Task1才能继续执行；而当Task1还在执行工作时，如果Task2又被唤醒准备执行，Task2会再次立即抢占CPU打断Task1。这样导致Task1的执行被频繁打断，其实际周期会变得不稳定且可能显著增加，因为Task1不仅要完成自己的工作和延迟时间，还要额外承受被Task2多次抢占而暂停的时间。Task2的周期相对稳定，因为它总是优先执行不会被Task1打断，但由于和Task1共享CPU资源，其执行也可能受到轻微影响。

#### 问题4：预期周期是否得到遵守？这是获得周期性任务的好方法吗？

预期周期没有得到遵守，测量到的实际周期（26.8ms和36.8ms）远大于预期的周期（10ms和20ms）。这不是获得周期性任务的好方法，因为`vTaskDelay()`只能保证任务在延迟时间后被唤醒，但无法控制任务的总体周期。实际周期取决于工作执行时间加上延迟时间，如果工作时间本身就超过了预期周期，那么周期性就无法保证。这种方法的主要问题是延迟是相对于调用`vTaskDelay()`的时刻计算的，而不是相对于任务上次开始执行的时刻，因此工作时间的变化会累积导致周期漂移。对于需要精确周期性执行的实时任务，应该使用`vTaskDelayUntil()`函数，它可以保证任务从固定的时间点开始周期性唤醒，而不受工作执行时间的影响。

---

### 2.2.2 第二种方法

**程序：** IF4_TP1_Q22b.ino

#### 问题1：与前一个程序有什么区别？

与Q22a程序相比，Q22b使用了`vTaskDelayUntil()`函数替代`vTaskDelay()`来实现周期性任务。每个任务在开始时调用`xTaskGetTickCount()`获取当前系统时间并保存在`xLastWakeTime`变量中，然后在每次循环结束时调用`vTaskDelayUntil(&xLastWakeTime, pdMS_TO_TICKS(period))`。这个函数会让任务在距离上次唤醒时间点的period毫秒后再次唤醒，而不是像`vTaskDelay()`那样从函数调用时刻开始计算延迟。这样可以保证任务的周期性更加精确，因为周期是相对于固定参考点计算的，不受任务工作执行时间波动的影响。

#### 问题2：任务1和任务2获得的周期是多少？解释原因。

通过示波器测量，Task1的周期为10ms（5ms工作+5ms不工作），Task2的周期为20ms（5ms工作+15ms不工作），完全符合代码中设定的预期周期。这个结果证明了`vTaskDelayUntil()`能够精确控制任务的周期性执行。原因是`vTaskDelayUntil()`会根据上次任务唤醒的时间点来计算下次唤醒时间，而不考虑任务实际执行了多长时间。即使工作时间（5ms）小于设定周期（10ms或20ms），调度器也会确保任务在精确的周期时间点被唤醒，剩余时间任务处于阻塞状态。由于nb_iterations=10000，工作时间约为5ms，远小于设定的周期，因此系统能够完美遵守预期周期。

#### 问题3：如果强制两个任务在同一个核心上运行，会发生什么？

当将两个任务都强制在同一个核心上运行时，观察到Task2保持20ms周期（5ms工作+15ms空白），而Task1的周期从10ms变成了20ms，且执行模式变为10ms工作+10ms不工作。这个现象的原因是Task2的优先级（10）高于Task1的优先级（1），当Task1正在执行时，如果Task2被唤醒需要执行，高优先级的Task2会立即抢占CPU打断Task1。此时Task1虽然被打断但仍然处于就绪状态等待执行（相当于"举手"表示需要CPU）。当Task2执行完毕进入阻塞状态后，Task1继续执行完成其工作。但在Task1执行期间，下一个10ms周期到了，Task1又被`vTaskDelayUntil()`唤醒，于是Task1再次"举手"等待执行。这样Task1累积了两次10ms周期的执行请求，当Task2不占用CPU时，Task1就会连续执行两次工作（两次5ms），因此出现了连续10ms工作的现象，最终呈现出20ms周期（10ms连续工作+10ms不工作）的模式。

#### 问题4：逐步增加nb_iterations以延长两个任务的工作时间。会发生什么？

当将nb_iterations从10000逐步增加到15000时，在两个任务分配到不同核心的情况下，观察到任务的周期保持不变（Task1仍为10ms，Task2仍为20ms），但是任务的占空比显著增加。Task1的占空比从原来的约50%（5ms工作/10ms周期）增加到约85%（约8.5ms工作/10ms周期），这说明工作时间从5ms增加到了8.5ms左右。`vTaskDelayUntil()`函数强制保持任务的周期性，即使工作时间增加，调度器也会确保任务在精确的周期时间点被唤醒。然而这种情况存在风险：如果继续增加nb_iterations使得工作时间达到或超过设定的周期时间（10ms或20ms），任务将无法在下一个周期开始前完成工作，导致错过截止时间（deadline miss）。这时周期性将被破坏，可能出现任务积压、系统响应延迟，甚至触发看门狗超时错误。因此在设计实时系统时，必须确保任务的最坏执行时间（WCET）小于其周期，以保证系统的可调度性。

#### 问题5：什么标准可以预测这个问题？

可以使用实时系统的可调度性分析标准来预测任务是否会错过截止时间。最基本的标准是**处理器利用率（CPU Utilization）**，计算公式为：U = Σ(Ci/Ti)，其中Ci是任务i的最坏执行时间（WCET），Ti是任务i的周期。对于固定优先级的抢占式调度（FreeRTOS使用的调度方式），如果处理器利用率U > 1，系统肯定不可调度，至少有一个任务会错过截止时间。在本实验中，当nb_iterations=10000时，C1≈5ms，T1=10ms，C2≈5ms，T2=20ms，所以U = 5/10 + 5/20 = 0.75 < 1，系统可调度。但当nb_iterations增加到15000时，C1≈8.5ms，所以U = 8.5/10 + 8.5/20 ≈ 1.275 > 1，系统不可调度，Task1会错过截止时间。更精确的可调度性判据包括**Liu & Layland界限**（对于n个任务，U ≤ n(2^(1/n)-1)）和**响应时间分析（Response Time Analysis）**，可以在U < 1的情况下进一步判断系统是否可调度。因此，在设计实时系统时，应该预先计算每个任务的WCET和周期，确保处理器利用率留有充足余量，以保证系统的可调度性和可靠性。

---

## 2.3 任务间同步

### 2.3.2 实验1

**程序：** IF4_TP1_Q23a.ino

该程序演示了使用二进制信号量进行任务间同步的机制。程序创建了两个任务Task1和Task2，它们通过一个二进制信号量进行同步协作。Task1（优先级1）每10ms周期性执行，完成工作后调用`xSemaphoreGive(semaphore)`释放信号量，相当于给Task2发送一个"可以开始工作"的信号。Task2（优先级10）在无限循环中调用`xSemaphoreTake(semaphore, 10)`尝试获取信号量，如果成功获取则执行工作，否则等待最多10个时钟周期。这种同步机制确保了Task2只有在Task1完成工作并释放信号量后才会执行，实现了任务间的顺序协调。两个任务被分配到不同的核心上运行（Task1在core 0，Task2在core 1），避免了优先级导致的抢占问题。信号量起到了"绿灯"的作用，Task1通过释放信号量告诉Task2"你现在可以执行了"，而Task2必须等待这个信号才能开始工作。

### 2.3.3 实验2

**程序：** IF4_TP1_Q23b.ino

#### 问题1：解释程序做了什么（使用示波器和串口控制台）。

程序创建了两个相同优先级（都是10）的任务Task1和Task2，分别在core 0和core 1上运行。每个任务都有自己的工作周期和访问"共享资源"的操作。Task1先工作1秒（delay(100次×10ms)），然后访问共享资源（切换GPIO 23引脚100次，每次间隔10ms，共1秒），之后延迟100ms再重复。Task2先工作10ms，然后访问共享资源（切换GPIO 19引脚100次，共1秒），之后延迟200ms再重复。从串口日志可以看到两个任务交替输出工作信息和访问共享资源的信息。在示波器上观察到信号非常不稳定，有时只有信号1，有时只有信号2，有时两个都有，非常混乱。大致模式是信号1每1.2秒有信号，持续约1秒后有0.2秒无信号；信号2有1秒有信号，1秒无信号的周期。

#### 问题2：什么地方工作不正常？

工作不正常的地方是两个任务可以同时访问"共享资源"。从日志中可以看到"vTask1 travaille sur la ressource partagée"和"vTask2 travaille sur la ressource partagée"会同时出现，这说明两个任务在并发地操作各自的GPIO引脚。虽然程序创建了互斥锁（xMutex），但是保护共享资源的关键代码（`xSemaphoreTake()`和`xSemaphoreGive()`）都被注释掉了，导致互斥锁没有起作用。两个任务可以同时执行各自对GPIO的操作，如果它们真的在访问同一个共享资源（比如共享变量或硬件设备），就会发生竞态条件（race condition），导致数据不一致或不可预测的行为。在示波器上看到的混乱信号和不稳定性正是因为缺少互斥保护，两个任务的GPIO操作互相干扰。

#### 问题3：取消第57-58行、65-66行、92-93行、100-101行的注释。解释发生了什么？

取消注释后，互斥锁的保护机制开始生效。从串口日志可以清楚地看到任务的执行顺序：一个任务先"verrouillé le mutex"（锁定互斥锁），然后访问共享资源，完成后"déverrouille le mutex"（解锁互斥锁），之后另一个任务才能锁定互斥锁并访问共享资源。日志显示Task1和Task2严格交替地访问共享资源，不再出现同时访问的情况。在示波器上观察到信号变得非常稳定：在2秒的大周期内，信号1和信号2交替地在各自的1秒时间段内有信号，形成规律的互斥访问模式。这证明了互斥锁成功地保护了共享资源，确保同一时刻只有一个任务可以访问该资源。当一个任务持有互斥锁时，另一个任务调用`xSemaphoreTake()`会被阻塞等待，直到互斥锁被释放。这种机制有效地避免了竞态条件，保证了共享资源访问的原子性和一致性，使得系统行为变得可预测和稳定。

### 2.3.4 实验3

**程序：** IF4_TP1_Q23c.ino

#### 问题1：解释程序做了什么。

该程序演示了优先级反转（Priority Inversion）问题及其解决方案。程序创建了三个不同优先级的任务都固定在core 0上运行：TaskBasse（低优先级5）、TaskInter（中优先级10）和TaskHaute（高优先级20）。三个任务有不同的启动延迟：TaskBasse延迟100ms后获取信号量并访问共享资源，TaskInter延迟500ms后执行不需要共享资源的独立工作，TaskHaute延迟1000ms后尝试获取信号量访问共享资源。程序通过模拟大量无用工作来延长任务执行时间，并记录每个任务的总执行时间。使用二进制信号量时，观察到的执行顺序是：TaskBasse先获取信号量开始工作，然后TaskInter启动并因为优先级更高而抢占TaskBasse执行完其工作（耗时1214ms），之后TaskBasse继续完成共享资源访问（总耗时2187ms），最后TaskHaute才能获取信号量执行（耗时1914ms）。可以看到TaskHaute虽然优先级最高，但被迫等待了低优先级的TaskBasse和中优先级的TaskInter，总等待时间超过3秒，这就是典型的优先级反转现象。

#### 问题2：将二进制信号量替换为互斥锁。解释区别是什么？

将`xSemaphoreCreateBinary()`替换为`xSemaphoreCreateMutex()`后，程序行为发生了显著变化。使用互斥锁时，TaskBasse的执行时间从2187ms减少到1472ms，TaskHaute的执行时间从1914ms减少到1199ms，而TaskInter的工作被延后到TaskHaute完成之后才执行。这个差异的原因是互斥锁具有优先级继承（Priority Inheritance）机制：当高优先级的TaskHaute尝试获取已被低优先级TaskBasse持有的互斥锁时，系统会临时将TaskBasse的优先级提升到与TaskHaute相同的级别（20），使TaskBasse不会被中优先级的TaskInter抢占，能够快速完成工作并释放互斥锁。一旦TaskBasse释放互斥锁，其优先级恢复到原来的5，TaskHaute立即获取互斥锁执行，最后才轮到TaskInter执行。而二进制信号量不具备优先级继承机制，导致持有信号量的低优先级任务仍然会被中优先级任务抢占，造成高优先级任务长时间等待。因此，在保护共享资源时应优先使用互斥锁而非二进制信号量，以避免优先级反转问题并提高系统的实时性能。

---
